{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mo72001/T5/blob/main/Copy_of_ANN_Model_Exercise_Iris.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cb8aaa37",
      "metadata": {
        "id": "cb8aaa37"
      },
      "source": [
        "# Building an ANN with the Iris Dataset\n",
        "    \n",
        "    ## Introduction\n",
        "    Artificial Neural Networks (ANNs) are a cornerstone of modern machine learning. In this lab, you will construct a simple ANN to classify iris plants into one of three species based on the length and width of their sepals and petals. This exercise will help you understand the basics of neural networks, including their architecture, activation functions, and the backpropagation algorithm for training.\n",
        "\n",
        "    ## Dataset Reference\n",
        "    The Iris dataset was introduced by the British statistician and biologist Ronald Fisher in 1936. It is widely used as a beginner's dataset for machine learning classification problems. You can access this dataset via the `sklearn.datasets` module.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9fca486d",
      "metadata": {
        "id": "9fca486d"
      },
      "source": [
        "## Part 1: Load and Explore the Data\n",
        "    ### Load the Dataset\n",
        "    **Hint**: Use `sklearn.datasets.load_iris()` to load the Iris dataset into your environment.\n",
        "\n",
        "    ### Explore the Data\n",
        "    **Hint**: Use `pandas` to examine the first few rows of the dataset and `matplotlib` or `seaborn` to visualize the feature distributions.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import load_iris\n"
      ],
      "metadata": {
        "id": "EuVn19cLC8r4"
      },
      "id": "EuVn19cLC8r4",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = load_iris()"
      ],
      "metadata": {
        "id": "sqJvpK31DpbL"
      },
      "id": "sqJvpK31DpbL",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "19dc3fd6",
      "metadata": {
        "id": "19dc3fd6"
      },
      "source": [
        "## Part 2: Prepare the Data\n",
        "    ### Split the Data into Training and Test Sets\n",
        "    **Hint**: Use `train_test_split` from `sklearn.model_selection` to divide the data into training and test sets.\n",
        "\n",
        "    ### Scale the Features\n",
        "    **Hint**: Standardize the features using `StandardScaler` from `sklearn.preprocessing`.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.data\n",
        "y = df.target"
      ],
      "metadata": {
        "id": "Axm42GPGFH4Q"
      },
      "id": "Axm42GPGFH4Q",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oo5gUQSWF-zL",
        "outputId": "9b1dde70-11cc-4cb8-9201-cb3e4dd6c494"
      },
      "id": "oo5gUQSWF-zL",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2],\n",
              "       [4.9, 3. , 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.3, 0.2],\n",
              "       [4.6, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.6, 1.4, 0.2],\n",
              "       [5.4, 3.9, 1.7, 0.4],\n",
              "       [4.6, 3.4, 1.4, 0.3],\n",
              "       [5. , 3.4, 1.5, 0.2],\n",
              "       [4.4, 2.9, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.1],\n",
              "       [5.4, 3.7, 1.5, 0.2],\n",
              "       [4.8, 3.4, 1.6, 0.2],\n",
              "       [4.8, 3. , 1.4, 0.1],\n",
              "       [4.3, 3. , 1.1, 0.1],\n",
              "       [5.8, 4. , 1.2, 0.2],\n",
              "       [5.7, 4.4, 1.5, 0.4],\n",
              "       [5.4, 3.9, 1.3, 0.4],\n",
              "       [5.1, 3.5, 1.4, 0.3],\n",
              "       [5.7, 3.8, 1.7, 0.3],\n",
              "       [5.1, 3.8, 1.5, 0.3],\n",
              "       [5.4, 3.4, 1.7, 0.2],\n",
              "       [5.1, 3.7, 1.5, 0.4],\n",
              "       [4.6, 3.6, 1. , 0.2],\n",
              "       [5.1, 3.3, 1.7, 0.5],\n",
              "       [4.8, 3.4, 1.9, 0.2],\n",
              "       [5. , 3. , 1.6, 0.2],\n",
              "       [5. , 3.4, 1.6, 0.4],\n",
              "       [5.2, 3.5, 1.5, 0.2],\n",
              "       [5.2, 3.4, 1.4, 0.2],\n",
              "       [4.7, 3.2, 1.6, 0.2],\n",
              "       [4.8, 3.1, 1.6, 0.2],\n",
              "       [5.4, 3.4, 1.5, 0.4],\n",
              "       [5.2, 4.1, 1.5, 0.1],\n",
              "       [5.5, 4.2, 1.4, 0.2],\n",
              "       [4.9, 3.1, 1.5, 0.2],\n",
              "       [5. , 3.2, 1.2, 0.2],\n",
              "       [5.5, 3.5, 1.3, 0.2],\n",
              "       [4.9, 3.6, 1.4, 0.1],\n",
              "       [4.4, 3. , 1.3, 0.2],\n",
              "       [5.1, 3.4, 1.5, 0.2],\n",
              "       [5. , 3.5, 1.3, 0.3],\n",
              "       [4.5, 2.3, 1.3, 0.3],\n",
              "       [4.4, 3.2, 1.3, 0.2],\n",
              "       [5. , 3.5, 1.6, 0.6],\n",
              "       [5.1, 3.8, 1.9, 0.4],\n",
              "       [4.8, 3. , 1.4, 0.3],\n",
              "       [5.1, 3.8, 1.6, 0.2],\n",
              "       [4.6, 3.2, 1.4, 0.2],\n",
              "       [5.3, 3.7, 1.5, 0.2],\n",
              "       [5. , 3.3, 1.4, 0.2],\n",
              "       [7. , 3.2, 4.7, 1.4],\n",
              "       [6.4, 3.2, 4.5, 1.5],\n",
              "       [6.9, 3.1, 4.9, 1.5],\n",
              "       [5.5, 2.3, 4. , 1.3],\n",
              "       [6.5, 2.8, 4.6, 1.5],\n",
              "       [5.7, 2.8, 4.5, 1.3],\n",
              "       [6.3, 3.3, 4.7, 1.6],\n",
              "       [4.9, 2.4, 3.3, 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3],\n",
              "       [5.2, 2.7, 3.9, 1.4],\n",
              "       [5. , 2. , 3.5, 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5],\n",
              "       [6. , 2.2, 4. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4],\n",
              "       [5.6, 2.9, 3.6, 1.3],\n",
              "       [6.7, 3.1, 4.4, 1.4],\n",
              "       [5.6, 3. , 4.5, 1.5],\n",
              "       [5.8, 2.7, 4.1, 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5],\n",
              "       [5.6, 2.5, 3.9, 1.1],\n",
              "       [5.9, 3.2, 4.8, 1.8],\n",
              "       [6.1, 2.8, 4. , 1.3],\n",
              "       [6.3, 2.5, 4.9, 1.5],\n",
              "       [6.1, 2.8, 4.7, 1.2],\n",
              "       [6.4, 2.9, 4.3, 1.3],\n",
              "       [6.6, 3. , 4.4, 1.4],\n",
              "       [6.8, 2.8, 4.8, 1.4],\n",
              "       [6.7, 3. , 5. , 1.7],\n",
              "       [6. , 2.9, 4.5, 1.5],\n",
              "       [5.7, 2.6, 3.5, 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1],\n",
              "       [5.5, 2.4, 3.7, 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2],\n",
              "       [6. , 2.7, 5.1, 1.6],\n",
              "       [5.4, 3. , 4.5, 1.5],\n",
              "       [6. , 3.4, 4.5, 1.6],\n",
              "       [6.7, 3.1, 4.7, 1.5],\n",
              "       [6.3, 2.3, 4.4, 1.3],\n",
              "       [5.6, 3. , 4.1, 1.3],\n",
              "       [5.5, 2.5, 4. , 1.3],\n",
              "       [5.5, 2.6, 4.4, 1.2],\n",
              "       [6.1, 3. , 4.6, 1.4],\n",
              "       [5.8, 2.6, 4. , 1.2],\n",
              "       [5. , 2.3, 3.3, 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3],\n",
              "       [5.7, 3. , 4.2, 1.2],\n",
              "       [5.7, 2.9, 4.2, 1.3],\n",
              "       [6.2, 2.9, 4.3, 1.3],\n",
              "       [5.1, 2.5, 3. , 1.1],\n",
              "       [5.7, 2.8, 4.1, 1.3],\n",
              "       [6.3, 3.3, 6. , 2.5],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [7.1, 3. , 5.9, 2.1],\n",
              "       [6.3, 2.9, 5.6, 1.8],\n",
              "       [6.5, 3. , 5.8, 2.2],\n",
              "       [7.6, 3. , 6.6, 2.1],\n",
              "       [4.9, 2.5, 4.5, 1.7],\n",
              "       [7.3, 2.9, 6.3, 1.8],\n",
              "       [6.7, 2.5, 5.8, 1.8],\n",
              "       [7.2, 3.6, 6.1, 2.5],\n",
              "       [6.5, 3.2, 5.1, 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9],\n",
              "       [6.8, 3. , 5.5, 2.1],\n",
              "       [5.7, 2.5, 5. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4],\n",
              "       [6.4, 3.2, 5.3, 2.3],\n",
              "       [6.5, 3. , 5.5, 1.8],\n",
              "       [7.7, 3.8, 6.7, 2.2],\n",
              "       [7.7, 2.6, 6.9, 2.3],\n",
              "       [6. , 2.2, 5. , 1.5],\n",
              "       [6.9, 3.2, 5.7, 2.3],\n",
              "       [5.6, 2.8, 4.9, 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8],\n",
              "       [6.7, 3.3, 5.7, 2.1],\n",
              "       [7.2, 3.2, 6. , 1.8],\n",
              "       [6.2, 2.8, 4.8, 1.8],\n",
              "       [6.1, 3. , 4.9, 1.8],\n",
              "       [6.4, 2.8, 5.6, 2.1],\n",
              "       [7.2, 3. , 5.8, 1.6],\n",
              "       [7.4, 2.8, 6.1, 1.9],\n",
              "       [7.9, 3.8, 6.4, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2],\n",
              "       [6.3, 2.8, 5.1, 1.5],\n",
              "       [6.1, 2.6, 5.6, 1.4],\n",
              "       [7.7, 3. , 6.1, 2.3],\n",
              "       [6.3, 3.4, 5.6, 2.4],\n",
              "       [6.4, 3.1, 5.5, 1.8],\n",
              "       [6. , 3. , 4.8, 1.8],\n",
              "       [6.9, 3.1, 5.4, 2.1],\n",
              "       [6.7, 3.1, 5.6, 2.4],\n",
              "       [6.9, 3.1, 5.1, 2.3],\n",
              "       [5.8, 2.7, 5.1, 1.9],\n",
              "       [6.8, 3.2, 5.9, 2.3],\n",
              "       [6.7, 3.3, 5.7, 2.5],\n",
              "       [6.7, 3. , 5.2, 2.3],\n",
              "       [6.3, 2.5, 5. , 1.9],\n",
              "       [6.5, 3. , 5.2, 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3],\n",
              "       [5.9, 3. , 5.1, 1.8]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_DofWi1OF7v2",
        "outputId": "68fd59ca-d4e7-4b3c-d532-fa877ac6ca5d"
      },
      "id": "_DofWi1OF7v2",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_val,X_val,y_train_val,y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "jpysPrv7EpfC"
      },
      "id": "jpysPrv7EpfC",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_train_val = scaler.fit_transform(X_train_val)\n",
        "X_val = scaler.transform(X_val)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "6lmWxW0sEUU0"
      },
      "id": "6lmWxW0sEUU0",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(y_train).plot(kind = 'bar')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "1ik-9QknMCgT",
        "outputId": "c329883b-b2e1-4dde-d23c-51436cf65cf2"
      },
      "id": "1ik-9QknMCgT",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "166c4101",
      "metadata": {
        "id": "166c4101"
      },
      "source": [
        "## Part 3: Build the ANN Model\n",
        "    ### Define the Model\n",
        "    **Hint**: Use `keras` to define a sequential model. Start with a single hidden layer with a ReLU activation function.\n",
        "\n",
        "    ### Compile the Model\n",
        "    **Hint**: Compile your model specifying an optimizer and loss function appropriate for classification.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model = Sequential([\n",
        "                    Dense(units = 20,activation = 'relu'),\n",
        "                    Dense(units = 3,activation = 'softmax')])\n",
        "\n",
        "\n",
        "model.compile(optimizer = 'adam', metrics=['acc'], loss = 'sparse_categorical_crossentropy')\n"
      ],
      "metadata": {
        "id": "_ee998JIHv3b"
      },
      "id": "_ee998JIHv3b",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "8dd17d04",
      "metadata": {
        "id": "8dd17d04"
      },
      "source": [
        "## Part 4: Train the Model\n",
        "    ### Train the Model\n",
        "    **Hint**: Fit the model on your training data with a reasonable number of epochs.\n",
        "\n",
        "    ### Evaluate the Model\n",
        "    **Hint**: Use the test data to evaluate your model and report the accuracy.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_val,y_train_val,epochs=50,validation_data=(X_val,y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rYUA8bCBJweu",
        "outputId": "07f2203d-6acc-442f-fd1c-5bf180cd0f49"
      },
      "id": "rYUA8bCBJweu",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 152ms/step - acc: 0.4453 - loss: 1.0302 - val_acc: 0.4167 - val_loss: 1.0547\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.4375 - loss: 1.0227 - val_acc: 0.4167 - val_loss: 1.0297\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - acc: 0.4674 - loss: 0.9928 - val_acc: 0.4167 - val_loss: 1.0062\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.4557 - loss: 0.9719 - val_acc: 0.4583 - val_loss: 0.9830\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.5013 - loss: 0.9388 - val_acc: 0.4583 - val_loss: 0.9609\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - acc: 0.5456 - loss: 0.8959 - val_acc: 0.5000 - val_loss: 0.9401\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.5573 - loss: 0.8914 - val_acc: 0.5833 - val_loss: 0.9199\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.5807 - loss: 0.8606 - val_acc: 0.5833 - val_loss: 0.9005\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - acc: 0.6068 - loss: 0.8526 - val_acc: 0.5833 - val_loss: 0.8816\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.6510 - loss: 0.8208 - val_acc: 0.6250 - val_loss: 0.8636\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.7396 - loss: 0.7700 - val_acc: 0.6250 - val_loss: 0.8466\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.6966 - loss: 0.7939 - val_acc: 0.6250 - val_loss: 0.8301\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - acc: 0.7409 - loss: 0.7852 - val_acc: 0.6250 - val_loss: 0.8145\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - acc: 0.7318 - loss: 0.7733 - val_acc: 0.6250 - val_loss: 0.7990\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.7357 - loss: 0.7435 - val_acc: 0.6250 - val_loss: 0.7841\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.7591 - loss: 0.7289 - val_acc: 0.6250 - val_loss: 0.7696\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.8034 - loss: 0.6902 - val_acc: 0.6250 - val_loss: 0.7560\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.7409 - loss: 0.7200 - val_acc: 0.7500 - val_loss: 0.7428\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.7865 - loss: 0.6868 - val_acc: 0.7500 - val_loss: 0.7301\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.8372 - loss: 0.6602 - val_acc: 0.7500 - val_loss: 0.7180\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - acc: 0.8086 - loss: 0.6769 - val_acc: 0.7500 - val_loss: 0.7060\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.8398 - loss: 0.6544 - val_acc: 0.7500 - val_loss: 0.6946\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - acc: 0.8477 - loss: 0.6395 - val_acc: 0.7500 - val_loss: 0.6837\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8932 - loss: 0.5906 - val_acc: 0.7500 - val_loss: 0.6734\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.8737 - loss: 0.5866 - val_acc: 0.7500 - val_loss: 0.6632\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.8659 - loss: 0.5852 - val_acc: 0.7500 - val_loss: 0.6534\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - acc: 0.8659 - loss: 0.6005 - val_acc: 0.7917 - val_loss: 0.6440\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.8581 - loss: 0.5746 - val_acc: 0.7917 - val_loss: 0.6350\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.8789 - loss: 0.5636 - val_acc: 0.7917 - val_loss: 0.6261\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.9102 - loss: 0.5266 - val_acc: 0.7917 - val_loss: 0.6175\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.8971 - loss: 0.5502 - val_acc: 0.7917 - val_loss: 0.6091\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.8464 - loss: 0.5424 - val_acc: 0.7917 - val_loss: 0.6009\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.8659 - loss: 0.5288 - val_acc: 0.7917 - val_loss: 0.5930\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.8581 - loss: 0.5200 - val_acc: 0.7917 - val_loss: 0.5853\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 0.8620 - loss: 0.5225 - val_acc: 0.7917 - val_loss: 0.5779\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 0.8503 - loss: 0.5020 - val_acc: 0.7917 - val_loss: 0.5705\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - acc: 0.8893 - loss: 0.4688 - val_acc: 0.7917 - val_loss: 0.5636\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.8346 - loss: 0.4882 - val_acc: 0.7917 - val_loss: 0.5568\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.8698 - loss: 0.4708 - val_acc: 0.7917 - val_loss: 0.5504\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.8737 - loss: 0.4682 - val_acc: 0.7917 - val_loss: 0.5440\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.8815 - loss: 0.4565 - val_acc: 0.7917 - val_loss: 0.5378\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 0.8776 - loss: 0.4459 - val_acc: 0.7917 - val_loss: 0.5319\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - acc: 0.8268 - loss: 0.4889 - val_acc: 0.7917 - val_loss: 0.5260\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 0.8503 - loss: 0.4556 - val_acc: 0.7917 - val_loss: 0.5201\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.8776 - loss: 0.4249 - val_acc: 0.7917 - val_loss: 0.5150\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.8776 - loss: 0.4147 - val_acc: 0.7917 - val_loss: 0.5099\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.8698 - loss: 0.4368 - val_acc: 0.7917 - val_loss: 0.5047\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.8737 - loss: 0.4165 - val_acc: 0.7917 - val_loss: 0.4998\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.8646 - loss: 0.4049 - val_acc: 0.7917 - val_loss: 0.4949\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - acc: 0.8568 - loss: 0.4065 - val_acc: 0.7917 - val_loss: 0.4900\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d339c8096c0>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a0f2d8bb",
      "metadata": {
        "id": "a0f2d8bb"
      },
      "source": [
        "## Part 5: Experiment and Improve\n",
        "    ### Tune the Model\n",
        "    **Hint**: Try adding more hidden layers or neurons, or use different activation functions and see if the accuracy improves.\n",
        "\n",
        "    ### Regularization and Dropout\n",
        "    **Hint**: Implement dropout or regularization techniques to improve the model's generalization.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import tensorflow as tf\n",
        "model = Sequential([\n",
        "                    Dense(units = 20,activation = 'relu'),\n",
        "                    Dense(units = 15,activation = 'relu'),\n",
        "                    Dense(units = 3,activation = 'softmax')])\n",
        "\n",
        "adm_opt = tf.keras.optimizers.Adam(learning_rate = 0.01)\n",
        "model.compile(optimizer = adm_opt, metrics=['acc'], loss = 'sparse_categorical_crossentropy')\n"
      ],
      "metadata": {
        "id": "vzB_pHgxOCpQ"
      },
      "id": "vzB_pHgxOCpQ",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train_val,y_train_val,epochs=50,validation_data=(X_val,y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qeK_E8byOpkz",
        "outputId": "c4958947-9a8c-4857-9eaa-59ca3bc94cf3"
      },
      "id": "qeK_E8byOpkz",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 107ms/step - acc: 0.3906 - loss: 1.2277 - val_acc: 0.7500 - val_loss: 0.7992\n",
            "Epoch 2/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.5911 - loss: 0.8163 - val_acc: 0.7917 - val_loss: 0.6281\n",
            "Epoch 3/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.6523 - loss: 0.6329 - val_acc: 0.7500 - val_loss: 0.5478\n",
            "Epoch 4/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.6341 - loss: 0.5945 - val_acc: 0.7917 - val_loss: 0.4996\n",
            "Epoch 5/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - acc: 0.7734 - loss: 0.5228 - val_acc: 0.8333 - val_loss: 0.4695\n",
            "Epoch 6/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.7995 - loss: 0.4600 - val_acc: 0.7917 - val_loss: 0.4577\n",
            "Epoch 7/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.8034 - loss: 0.4214 - val_acc: 0.7500 - val_loss: 0.4603\n",
            "Epoch 8/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.7956 - loss: 0.3863 - val_acc: 0.7500 - val_loss: 0.4487\n",
            "Epoch 9/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - acc: 0.8177 - loss: 0.3626 - val_acc: 0.7917 - val_loss: 0.4102\n",
            "Epoch 10/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.7943 - loss: 0.3587 - val_acc: 0.8333 - val_loss: 0.3634\n",
            "Epoch 11/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.8464 - loss: 0.3088 - val_acc: 0.8750 - val_loss: 0.3309\n",
            "Epoch 12/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - acc: 0.8776 - loss: 0.2795 - val_acc: 0.9167 - val_loss: 0.3064\n",
            "Epoch 13/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 0.8945 - loss: 0.2858 - val_acc: 0.9167 - val_loss: 0.2827\n",
            "Epoch 14/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.8828 - loss: 0.2741 - val_acc: 0.9167 - val_loss: 0.2647\n",
            "Epoch 15/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - acc: 0.8633 - loss: 0.2512 - val_acc: 0.8750 - val_loss: 0.2637\n",
            "Epoch 16/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - acc: 0.8607 - loss: 0.2290 - val_acc: 0.8750 - val_loss: 0.2507\n",
            "Epoch 17/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - acc: 0.8997 - loss: 0.2223 - val_acc: 0.9167 - val_loss: 0.2287\n",
            "Epoch 18/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.9805 - loss: 0.1702 - val_acc: 0.9167 - val_loss: 0.2111\n",
            "Epoch 19/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.9688 - loss: 0.1578 - val_acc: 0.9583 - val_loss: 0.2114\n",
            "Epoch 20/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.9727 - loss: 0.1384 - val_acc: 0.9583 - val_loss: 0.2070\n",
            "Epoch 21/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 0.9779 - loss: 0.1340 - val_acc: 0.9167 - val_loss: 0.2211\n",
            "Epoch 22/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.9844 - loss: 0.1026 - val_acc: 0.9167 - val_loss: 0.2316\n",
            "Epoch 23/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.9740 - loss: 0.1157 - val_acc: 0.9167 - val_loss: 0.2083\n",
            "Epoch 24/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.9857 - loss: 0.0835 - val_acc: 0.9167 - val_loss: 0.1931\n",
            "Epoch 25/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.9779 - loss: 0.0752 - val_acc: 0.8750 - val_loss: 0.1947\n",
            "Epoch 26/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.9779 - loss: 0.0743 - val_acc: 0.8750 - val_loss: 0.2087\n",
            "Epoch 27/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - acc: 0.9896 - loss: 0.0599 - val_acc: 0.8750 - val_loss: 0.2334\n",
            "Epoch 28/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.9779 - loss: 0.0624 - val_acc: 0.8750 - val_loss: 0.2058\n",
            "Epoch 29/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.9818 - loss: 0.0466 - val_acc: 0.8750 - val_loss: 0.1786\n",
            "Epoch 30/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - acc: 0.9831 - loss: 0.0581 - val_acc: 0.9167 - val_loss: 0.2063\n",
            "Epoch 31/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.9661 - loss: 0.0533 - val_acc: 0.9167 - val_loss: 0.2217\n",
            "Epoch 32/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - acc: 0.9818 - loss: 0.0386 - val_acc: 0.9167 - val_loss: 0.2332\n",
            "Epoch 33/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - acc: 0.9779 - loss: 0.0381 - val_acc: 0.9167 - val_loss: 0.2311\n",
            "Epoch 34/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - acc: 0.9948 - loss: 0.0370 - val_acc: 0.9167 - val_loss: 0.2244\n",
            "Epoch 35/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 0.9948 - loss: 0.0292 - val_acc: 0.9167 - val_loss: 0.2348\n",
            "Epoch 36/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - acc: 0.9831 - loss: 0.0340 - val_acc: 0.9167 - val_loss: 0.2107\n",
            "Epoch 37/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 1.0000 - loss: 0.0232 - val_acc: 0.9167 - val_loss: 0.2187\n",
            "Epoch 38/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - acc: 1.0000 - loss: 0.0256 - val_acc: 0.9167 - val_loss: 0.2492\n",
            "Epoch 39/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - acc: 0.9948 - loss: 0.0263 - val_acc: 0.9167 - val_loss: 0.2798\n",
            "Epoch 40/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - acc: 0.9909 - loss: 0.0313 - val_acc: 0.9167 - val_loss: 0.2637\n",
            "Epoch 41/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - acc: 1.0000 - loss: 0.0222 - val_acc: 0.9167 - val_loss: 0.2551\n",
            "Epoch 42/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - acc: 1.0000 - loss: 0.0220 - val_acc: 0.9167 - val_loss: 0.2525\n",
            "Epoch 43/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 1.0000 - loss: 0.0269 - val_acc: 0.9167 - val_loss: 0.2416\n",
            "Epoch 44/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - acc: 1.0000 - loss: 0.0286 - val_acc: 0.9167 - val_loss: 0.2966\n",
            "Epoch 45/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - acc: 1.0000 - loss: 0.0260 - val_acc: 0.9167 - val_loss: 0.3153\n",
            "Epoch 46/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - acc: 1.0000 - loss: 0.0189 - val_acc: 0.9167 - val_loss: 0.3078\n",
            "Epoch 47/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 1.0000 - loss: 0.0272 - val_acc: 0.9167 - val_loss: 0.2717\n",
            "Epoch 48/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - acc: 1.0000 - loss: 0.0251 - val_acc: 0.9167 - val_loss: 0.2819\n",
            "Epoch 49/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - acc: 1.0000 - loss: 0.0179 - val_acc: 0.9167 - val_loss: 0.3188\n",
            "Epoch 50/50\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - acc: 1.0000 - loss: 0.0189 - val_acc: 0.9167 - val_loss: 0.2990\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7d33998a8dc0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "iSI4fcm4Q35I",
        "outputId": "0ad954a1-7396-41a6-e436-c7296fb3d77a"
      },
      "id": "iSI4fcm4Q35I",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m20\u001b[0m)                    │             \u001b[38;5;34m100\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m15\u001b[0m)                    │             \u001b[38;5;34m315\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m3\u001b[0m)                     │              \u001b[38;5;34m48\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                     │              <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,391\u001b[0m (5.44 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,391</span> (5.44 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m463\u001b[0m (1.81 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">463</span> (1.81 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m928\u001b[0m (3.63 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">928</span> (3.63 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ab398a2",
      "metadata": {
        "id": "5ab398a2"
      },
      "source": [
        "\n",
        "## Part 4: Model Evaluation\n",
        "### Evaluate the Model\n",
        "To effectively evaluate your artificial neural network, consider the following metrics:\n",
        "- **Accuracy**: This is the fraction of predictions our model got right.\n",
        "- **Confusion Matrix**: A table used to describe the performance of a classification model on a set of test data for which the true values are known.\n",
        "- **Precision, Recall, and F1-Score**: These metrics provide more insight into the types of errors made by the classifier.\n",
        "**Hint**: Use `classification_report` and `confusion_matrix` from `sklearn.metrics` to calculate these metrics.\n",
        "\n",
        "### Visualize Model Performance\n",
        "Visualizing the learning curves (loss and accuracy over epochs) can provide insights into the training process, such as whether the model is fitting or overfitting.\n",
        "**Hint**: Use `matplotlib.pyplot` to plot training and validation loss and accuracy.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "y_pred1 = model.predict(X_val)\n",
        "y_pred = np.argmax(y_pred1,axis=1)\n",
        "print(classification_report(y_val,y_pred))\n",
        "print(confusion_matrix(y_val,y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07FAkGxgQSIC",
        "outputId": "39a322c4-1751-43ae-eae8-8c48b39de86e"
      },
      "id": "07FAkGxgQSIC",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         8\n",
            "           1       1.00      0.82      0.90        11\n",
            "           2       0.71      1.00      0.83         5\n",
            "\n",
            "    accuracy                           0.92        24\n",
            "   macro avg       0.90      0.94      0.91        24\n",
            "weighted avg       0.94      0.92      0.92        24\n",
            "\n",
            "[[8 0 0]\n",
            " [0 9 2]\n",
            " [0 0 5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac12bf89",
      "metadata": {
        "id": "ac12bf89"
      },
      "source": [
        "## Conclusion\n",
        "    Summarize what the learner should have gained from this lab, including a better understanding of how ANNs work and how they can be applied to real-world classification problems.\n",
        "    "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}