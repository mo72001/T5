{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mo72001/T5/blob/main/Practice_of_Motion_Detection_Exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe5bacbb",
      "metadata": {
        "id": "fe5bacbb"
      },
      "source": [
        "# Exercise: Implementing Motion Detection Using Background Subtraction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a3332331",
      "metadata": {
        "id": "a3332331"
      },
      "source": [
        "### Objective"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e17c3591",
      "metadata": {
        "id": "e17c3591"
      },
      "source": [
        "In this exercise, you will implement motion detection in a video using background subtraction. Follow the steps outlined below and write the corresponding code for each step."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2309fa4f",
      "metadata": {
        "id": "2309fa4f"
      },
      "source": [
        "### Step 1: Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n"
      ],
      "metadata": {
        "id": "vwqPv3M2l8nz"
      },
      "id": "vwqPv3M2l8nz",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a9183a82",
      "metadata": {
        "id": "a9183a82"
      },
      "source": [
        "### Step 2: Set Up Video Capture"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "43ada6fe",
      "metadata": {
        "id": "43ada6fe"
      },
      "source": [
        "Initialize the video capture object by loading the video file (e.g., `video.mp4`). This object will allow you to read frames from the video."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cap = cv2.VideoCapture('/content/Motion_Detection_Test.mp4')\n"
      ],
      "metadata": {
        "id": "5YTx_g-fl-QY"
      },
      "id": "5YTx_g-fl-QY",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "0072f6cf",
      "metadata": {
        "id": "0072f6cf"
      },
      "source": [
        "### Step 3: Define the Video Writer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8f32d9d6",
      "metadata": {
        "id": "8f32d9d6"
      },
      "source": [
        "Set up a `VideoWriter` object to save the processed video with motion detection. Choose the appropriate codec (e.g., `'mp4v'`) and specify the frame rate and resolution for the output video."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out = cv2.VideoWriter('motion_output.mp4', fourcc, 20.0, (600, 500))\n"
      ],
      "metadata": {
        "id": "exSdbEE5l_ut"
      },
      "id": "exSdbEE5l_ut",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f5d81bbd",
      "metadata": {
        "id": "f5d81bbd"
      },
      "source": [
        "### Step 4: Create the Background Subtractor"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ddd55e96",
      "metadata": {
        "id": "ddd55e96"
      },
      "source": [
        "Use OpenCV's MOG2 background subtractor to create a background model that will help detect moving objects. Set `detectShadows=True` to improve detection accuracy by accounting for shadows."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fgbg = cv2.createBackgroundSubtractorMOG2(detectShadows=True)\n"
      ],
      "metadata": {
        "id": "nr_7PlafmA1H"
      },
      "id": "nr_7PlafmA1H",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "11c3ee89",
      "metadata": {
        "id": "11c3ee89"
      },
      "source": [
        "### Step 5: Process the Video Frame by Frame"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6e2c952d",
      "metadata": {
        "id": "6e2c952d"
      },
      "source": [
        "1. In a loop, capture each frame from the video.\n",
        "2. Resize the frame for consistency.\n",
        "3. Apply the background subtractor to detect moving objects in the frame.\n",
        "4. Create a binary thresholded image to isolate the moving objects.\n",
        "5. Apply morphological operations like erosion and dilation to reduce noise and strengthen the detected areas.\n",
        "6. Detect contours (boundaries) of the moving objects.\n",
        "7. For each contour, calculate its area and filter out small movements by considering only contours with areas greater than a certain threshold (e.g., 1200).\n",
        "8. Draw rectangles around the detected moving objects and annotate the motion."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "while True:\n",
        "    success, img = cap.read()\n",
        "\n",
        "    if success:\n",
        "        img = cv2.resize(img, (600, 500))\n",
        "\n",
        "        fgmask = fgbg.apply(img)\n",
        "\n",
        "        _, thresh = cv2.threshold(fgmask.copy(), 180, 255, cv2.THRESH_BINARY)\n",
        "\n",
        "        kernel = np.ones((6, 6), np.uint8)\n",
        "\n",
        "        thresh = cv2.erode(thresh, kernel)\n",
        "\n",
        "        thresh = cv2.dilate(thresh, None, iterations=6)\n",
        "\n",
        "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "        for contour in contours:\n",
        "            area = cv2.contourArea(contour)\n",
        "\n",
        "            if area > 1300:\n",
        "                x, y, w, h = cv2.boundingRect(contour)\n",
        "\n",
        "                cv2.rectangle(img, (x, y), (x + w, y + h), (255, 0, 255), 3)\n",
        "                cv2.putText(img, 'MOTION DETECTED', (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "        out.write(img)\n",
        "\n",
        "    else:\n",
        "        break\n"
      ],
      "metadata": {
        "id": "Iyae2b1lmBlS"
      },
      "id": "Iyae2b1lmBlS",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "260f89b2",
      "metadata": {
        "id": "260f89b2"
      },
      "source": [
        "### Step 6: Release Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "64a70401",
      "metadata": {
        "id": "64a70401"
      },
      "source": [
        "After processing all the frames, release the video capture and writer objects to free up system resources. Close any OpenCV windows that were opened during the process."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "\n",
        "cv2.destroyAllWindows()\n"
      ],
      "metadata": {
        "id": "cnuY8pmNmM_6"
      },
      "id": "cnuY8pmNmM_6",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "66aae989",
      "metadata": {
        "id": "66aae989"
      },
      "source": [
        "### Bonus Challenge"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "579a8ce5",
      "metadata": {
        "id": "579a8ce5"
      },
      "source": [
        "Try experimenting with different threshold values, kernel sizes, or codecs to optimize the motion detection and improve the output video quality."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}